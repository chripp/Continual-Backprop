defaults:
  - _self_
  - random: seed1
  - algorithm: ppo
#  - override hydra/launcher: joblib

hydra:
  sweep:
    dir: hydra_output/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.runtime.choices.algorithm}/${hydra.runtime.choices.random}
  job:
    chdir: True
#  launcher:
#    n_jobs: 6

name: ${hydra:runtime.choices.algorithm}_${hydra:runtime.choices.random}

seed_name: ${hydra:runtime.choices.random}

total_timesteps: 200000
n_jumps: 2
n_envs: 8
train_max_steps: 2000
model_dir: ./
ages_dir: ./ages
video_dir: ./video

algorithm:
  settings:
    n_steps: 4096
    n_epochs: 10
    batch_size: 128
    gae_lambda: 0.95
    gamma: 0.99
    clip_range: 0.2
    learning_rate: 1e-4
    tensorboard_log: ${hydra:runtime.cwd}/${hydra:sweep.dir}/tensorboard
    device: cuda
    policy_kwargs:
      net_arch: 
        - pi: [256, 256]
          vf: [256, 256]
      activation_fn: Tanh
      optimizer_kwargs:
        betas: [0.9, 0.999]

eval:
  max_steps: 2000
  n_eval_episodes: 1
  deterministic: True

wandb:
  group: ${hydra:runtime.choices.algorithm}
  mode: online #offline
  dir: ${hydra:runtime.cwd}/${hydra:sweep.dir}
  gradient_save_freq: 1000