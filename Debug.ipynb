{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e826cd33-f6bb-435e-8a38-c6fe921a4f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\anaconda3\\envs\\cbp\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from stable_baselines3.ppo import PPO\n",
    "\n",
    "from cppo import CPPO_Policy\n",
    "from env import SlidingAntEnv\n",
    "\n",
    "import gym\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d61723c-f91a-4461-b52e-c4a102e51c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[42]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "env.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aa073c7-0f1c-4a21-8abe-a3f441c1f171",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo = PPO(\"MlpPolicy\", env, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c45e37be-3c86-4621-8629-b7f6f98d7246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x20859b184c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo.learn(2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0554eb84-e050-408d-bca4-3b104593607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = copy.deepcopy(ppo.rollout_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb0a884-6b31-47e2-b31e-8bcf08f4455c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d27b3f3-9317-4958-9c32-733c2387a07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, <stable_baselines3.common.callbacks.CallbackList at 0x20859d17250>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env1 = gym.make('CartPole-v1')\n",
    "env1.seed(42)\n",
    "ppo_normal = PPO(\"MlpPolicy\", env1, seed=42)\n",
    "ppo_normal._setup_learn(2048, env1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aab5df0c-3e17-4f3c-bf84-e9649c563101",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_original_params = ppo_normal.policy.parameters_to_vector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1b01219-7416-4ea0-af82-4599652b442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "ppo_normal.rollout_buffer = copy.deepcopy(buffer)\n",
    "ppo_normal.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de6ea464-06ba-4645-a514-e8bb094d43aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_trained_params = ppo_normal.policy.parameters_to_vector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "434c2402-9521-47ed-a4a5-e9dbe8d3ac68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "794c6070-5430-4a7c-acc6-7ce915c8abc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from typing import List, Optional\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "class CAdam(Adam):\n",
    "    r\"\"\"\n",
    "    Barebone Adam adaptation with 'step' parameter for each weight in a parameter Tensor, instead of one number for the whole Tensor\n",
    "    \"\"\"\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"Performs a single optimization step.\n",
    "\n",
    "        Args:\n",
    "            closure (callable, optional): A closure that reevaluates the model\n",
    "                and returns the loss.\n",
    "        \"\"\"\n",
    "        self._cuda_graph_capture_health_check()\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            with torch.enable_grad():\n",
    "                loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            params_with_grad = []\n",
    "            grads = []\n",
    "            exp_avgs = []\n",
    "            exp_avg_sqs = []\n",
    "            max_exp_avg_sqs = []\n",
    "            state_steps = []\n",
    "            beta1, beta2 = group['betas']\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is not None:\n",
    "                    params_with_grad.append(p)\n",
    "                    if p.grad.is_sparse:\n",
    "                        raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n",
    "                    grads.append(p.grad)\n",
    "\n",
    "                    state = self.state[p]\n",
    "                    # Lazy state initialization\n",
    "                    if len(state) == 0:\n",
    "                        ### CHANGED ###\n",
    "                        #state['step'] = torch.zeros((1,), dtype=torch.float, device=p.device) \\\n",
    "                        #    if self.defaults['capturable'] else torch.tensor(0)\n",
    "                        state['step'] = torch.zeros_like(p, memory_format=torch.preserve_format, device=p.device)\n",
    "                        ###############\n",
    "                        \n",
    "                        \n",
    "                        # Exponential moving average of gradient values\n",
    "                        state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format, device=p.device)\n",
    "                        # Exponential moving average of squared gradient values\n",
    "                        state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format, device=p.device)\n",
    "                        if group['amsgrad']:\n",
    "                            # Maintains max of all exp. moving avg. of sq. grad. values\n",
    "                            state['max_exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
    "\n",
    "                    exp_avgs.append(state['exp_avg'])\n",
    "                    exp_avg_sqs.append(state['exp_avg_sq'])\n",
    "\n",
    "                    if group['amsgrad']:\n",
    "                        max_exp_avg_sqs.append(state['max_exp_avg_sq'])\n",
    "\n",
    "                    state_steps.append(state['step'])\n",
    "\n",
    "            cadam(params_with_grad,\n",
    "                 grads,\n",
    "                 exp_avgs,\n",
    "                 exp_avg_sqs,\n",
    "                 max_exp_avg_sqs,\n",
    "                 state_steps,\n",
    "                 amsgrad=group['amsgrad'],\n",
    "                 beta1=beta1,\n",
    "                 beta2=beta2,\n",
    "                 lr=group['lr'],\n",
    "                 weight_decay=group['weight_decay'],\n",
    "                 eps=group['eps'],\n",
    "                 maximize=group['maximize'],\n",
    "                 foreach=group['foreach'],\n",
    "                 capturable=group['capturable'])\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "def cadam(params: List[Tensor],\n",
    "         grads: List[Tensor],\n",
    "         exp_avgs: List[Tensor],\n",
    "         exp_avg_sqs: List[Tensor],\n",
    "         max_exp_avg_sqs: List[Tensor],\n",
    "         state_steps: List[Tensor],\n",
    "         # kwonly args with defaults are not supported by functions compiled with torchscript issue #70627\n",
    "         # setting this as kwarg for now as functional API is compiled by torch/distributed/optim\n",
    "         foreach: bool = None,\n",
    "         capturable: bool = False,\n",
    "         *,\n",
    "         amsgrad: bool,\n",
    "         beta1: float,\n",
    "         beta2: float,\n",
    "         lr: float,\n",
    "         weight_decay: float,\n",
    "         eps: float,\n",
    "         maximize: bool):\n",
    "    r\"\"\"Functional API that performs Adam algorithm computation.\n",
    "    See :class:`~torch.optim.Adam` for details.\n",
    "    \"\"\"\n",
    "\n",
    "    if not all([isinstance(t, torch.Tensor) for t in state_steps]):\n",
    "        raise RuntimeError(\"API has changed, `state_steps` argument must contain a list of singleton tensors\")\n",
    "\n",
    "    if foreach is None:\n",
    "        # Placeholder for more complex foreach logic to be added when value is not set\n",
    "        foreach = False\n",
    "\n",
    "    if foreach and torch.jit.is_scripting():\n",
    "        raise RuntimeError('torch.jit.script not supported with foreach optimizers')\n",
    "\n",
    "    if foreach and not torch.jit.is_scripting():\n",
    "        ### CHANGED ###\n",
    "        #func = _multi_tensor_adam\n",
    "        raise NotImplementedError()\n",
    "        ###############\n",
    "    else:\n",
    "        func = _single_tensor_cadam\n",
    "\n",
    "    func(params,\n",
    "         grads,\n",
    "         exp_avgs,\n",
    "         exp_avg_sqs,\n",
    "         max_exp_avg_sqs,\n",
    "         state_steps,\n",
    "         amsgrad=amsgrad,\n",
    "         beta1=beta1,\n",
    "         beta2=beta2,\n",
    "         lr=lr,\n",
    "         weight_decay=weight_decay,\n",
    "         eps=eps,\n",
    "         maximize=maximize,\n",
    "         capturable=capturable)\n",
    "\n",
    "@torch.jit.script\n",
    "def _single_tensor_cadam(params: List[Tensor],\n",
    "                        grads: List[Tensor],\n",
    "                        exp_avgs: List[Tensor],\n",
    "                        exp_avg_sqs: List[Tensor],\n",
    "                        max_exp_avg_sqs: List[Tensor],\n",
    "                        state_steps: List[Tensor],\n",
    "                        *,\n",
    "                        amsgrad: bool,\n",
    "                        beta1: float,\n",
    "                        beta2: float,\n",
    "                        lr: float,\n",
    "                        weight_decay: float,\n",
    "                        eps: float,\n",
    "                        maximize: bool,\n",
    "                        capturable: bool):\n",
    "    \n",
    "    for i, param in enumerate(params):\n",
    "\n",
    "        grad = grads[i] if not maximize else -grads[i]\n",
    "        exp_avg = exp_avgs[i]\n",
    "        exp_avg_sq = exp_avg_sqs[i]\n",
    "        step = state_steps[i]\n",
    "\n",
    "        if capturable:\n",
    "            assert param.is_cuda and step.is_cuda, \"If capturable=True, params and state_steps must be CUDA tensors.\"\n",
    "            \n",
    "        step.add_(1)\n",
    "        if weight_decay != 0:\n",
    "            grad = grad.add(param, alpha=weight_decay)\n",
    "            \n",
    "        exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n",
    "        exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n",
    "        \n",
    "        bias_correction1 = 1 - torch.pow(beta1, step)\n",
    "        bias_correction2 = 1 - torch.pow(beta2, step)\n",
    "        bias_correction2_sqrt = bias_correction2.sqrt()\n",
    "        \n",
    "        step_size = lr / bias_correction1\n",
    "        \n",
    "        denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add(eps)\n",
    "        param.sub_((exp_avg / denom).mul(step_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "780c9ea9-1227-45b1-9640-7cbb8034291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cadam import CAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0433724d-b283-4f0b-8579-8326818c669c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, <stable_baselines3.common.callbacks.CallbackList at 0x208012fa0a0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env2 = gym.make('CartPole-v1')\n",
    "env2.seed(42)\n",
    "ppo_cppo = PPO(CPPO_Policy, env2, seed=42, policy_kwargs={'optimizer_kwargs':{'eps':1e-5, 'rho': 0, 'm': 1}}) # SB3 sets custom eps for Adam\n",
    "ppo_cppo._setup_learn(2048, env2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6de1a495-874c-4f56-bf3a-0aeef0329cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cppo_original_params = ppo_cppo.policy.parameters_to_vector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0cdd582d-9771-48d1-b1fe-8ff83da98c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "ppo_cppo.rollout_buffer = copy.deepcopy(buffer)\n",
    "ppo_cppo.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "adf4160d-4311-49a3-95f8-cb420c000df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cppo_trained_params = ppo_cppo.policy.parameters_to_vector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc92bfb-54b8-423f-a5e8-bf92d36ca312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4128e708-2bf4-4c20-baad-1b5ddb46aab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ppo_original_params == cppo_original_params).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1f878aa4-da7a-441a-af7d-ffdf1ca7e93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(ppo_trained_params, cppo_trained_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14977c6a-d39d-459e-90ce-fd6237142a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04164303,  0.32055363,  0.25014526, ...,  0.20720258,\n",
       "       -0.16821611,  0.05669835], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo_trained_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ca9784a0-9e4d-4565-8cca-80af0bed63bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04164306,  0.32055348,  0.2501452 , ...,  0.20720248,\n",
       "       -0.16821593,  0.05669831], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cppo_trained_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b60a8ee-4f1d-4bcc-9998-14443fe43718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1846423e-06"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ppo_trained_params - cppo_trained_params)[~np.isclose(ppo_trained_params, cppo_trained_params)].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24d4145-fe41-489b-b18c-000f6ef7dae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48266540-4b89-4f88-a3cd-2d93731664a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    eps: 1e-05\n",
       "    foreach: None\n",
       "    lr: 0.0003\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo_normal.policy.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3579ab-3325-4fd6-87b8-9c140aa6e459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CBP (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    eps: 1e-05\n",
       "    foreach: None\n",
       "    lr: 0.0003\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo_cppo.policy.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b6b253-474f-477a-9f1c-d0821e2943f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cbp",
   "language": "python",
   "name": "conda-env-cbp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
